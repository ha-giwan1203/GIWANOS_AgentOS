#!/usr/bin/env python3
"""ğŸ“„ scripts/embed_test.py

ì •ê·œí™”ëœ NDâ€‘JSON ìƒ˜í”Œì„ ì½ì–´ ì„ë² ë”© â†’ ê²€ìƒ‰ê¹Œì§€ â€˜ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸â€™.
ì¤‘ì²© JSONì„ íŒŒì‹±í•˜ì—¬ ì •í™•í•œ í•„ë“œë¥¼ ì„ë² ë”©ì— ì‚¬ìš© (ìµœì¢… ìˆ˜ì •ë³¸)
"""

import argparse, itertools, json, os, sys
from openai import OpenAI
import numpy as np
import faiss
import re
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

sys.path.append(os.path.abspath("modules/core"))

def preprocess(text):
    text = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", "", text)
    return text.strip()

def get_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response.data[0].embedding

class EmbeddingManager:
    def __init__(self):
        self.embeddings = []
        self.records = []
        self.dimension = 1536
        self.index = faiss.IndexFlatL2(self.dimension)

    def extract_meaningful_text(self, record):
        text = record.get('text', '')
        try:
            inner_json = json.loads(text)
            meaningful_text = inner_json.get('memory') or inner_json.get('text', '')
        except json.JSONDecodeError:
            meaningful_text = text
        return meaningful_text

    def build_index_from_ndjson(self, ndjson_path):
        with open(ndjson_path, encoding="utf-8") as f:
            for line in f:
                record = json.loads(line)
                meaningful_text = self.extract_meaningful_text(record)
                embedding = get_embedding(preprocess(meaningful_text))
                self.embeddings.append(embedding)
                self.records.append(record)
        embeddings_array = np.array(self.embeddings, dtype='float32')
        self.index.add(embeddings_array)

    def query_similar_docs(self, query, top_k=3):
        query_embedding = np.array([get_embedding(preprocess(query))], dtype='float32')
        distances, indices = self.index.search(query_embedding, top_k)
        results = []
        for idx, dist in zip(indices[0], distances[0]):
            similarity = 1 / (1 + dist)
            results.append({
                'similarity': similarity,
                'record': self.records[idx]
            })
        return results

def main():
    p = argparse.ArgumentParser()
    p.add_argument("-i", "--input", required=True, help="normalised NDâ€‘JSON")
    p.add_argument("-n", "--num", type=int, default=10, help="ìƒ˜í”Œ ë ˆì½”ë“œ ìˆ˜")
    p.add_argument("-q", "--query", default="ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬ ë°©ë²•?")
    p.add_argument("-k", "--top-k", type=int, default=3)
    args = p.parse_args()

    tmp = "_sample.ndjson"
    with open(args.input, encoding="utf-8") as src, \
         open(tmp, "w", encoding="utf-8") as dst:
        dst.writelines(itertools.islice(src, args.num))

    em = EmbeddingManager()
    em.build_index_from_ndjson(tmp)

    print(f"ğŸ” ì¿¼ë¦¬: {args.query}")
    print(f"ìƒìœ„ {args.top_k}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼:\n")

    for r in em.query_similar_docs(args.query, top_k=args.top_k):
        meaningful_text = em.extract_meaningful_text(r['record'])
        print(f"{r['similarity']:.3f} | {meaningful_text[:80]}...")

    os.remove(tmp)
    print("âœ… smoke test complete")

if __name__ == "__main__":
    main()
