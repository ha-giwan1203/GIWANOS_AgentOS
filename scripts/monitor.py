# [ACTIVE] VELOS ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ - ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì¸í„°í˜ì´ìŠ¤
import os, json, time, re, threading, queue, base64, urllib.parse
from pathlib import Path
from datetime import datetime
import streamlit as st
import pandas as pd

st.set_page_config(page_title="VELOS ëŒ€ì‹œë³´ë“œ", layout="wide")

# ---------- ê³µí†µ ìŠ¤íƒ€ì¼ ----------
def _inject_base_css():
    st.markdown("""
    <style>
      .role-badge {
        display:inline-block; padding:2px 8px; border-radius:10px;
        font-size:12px; font-weight:600; margin-right:6px;
      }
      .role-user { background:#dbeafe; color:#1e40af; }
      .role-assistant { background:#dcfce7; color:#166534; }
      .role-system { background:#e5e7eb; color:#374151; }
      .chat-item {
        border:1px solid #1f2937; border-radius:10px; padding:10px 12px;
        margin:6px 0; background:#0b1220;
      }
      .log-error { color:#fecaca; }
      .log-warn  { color:#fde68a; }
      .log-info  { color:#bfdbfe; }
      .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono","Courier New", monospace; }
    </style>
    """, unsafe_allow_html=True)

# ---------- íŒŒì¼ ìœ í‹¸ ----------
def list_files(folder: Path, pattern: str):
    if not folder.exists():
        return []
    return sorted(folder.glob(pattern))

def read_text(path: Path, tail_lines=None):
    if not path.exists():
        return ""
    txt = path.read_text(encoding="utf-8", errors="ignore")
    if tail_lines and tail_lines > 0:
        return "\n".join(txt.splitlines()[-tail_lines:])
    return txt

# ---------- ë¡œê·¸ íŒŒì‹± ----------
LOG_LINE = re.compile(r"(?P<ts>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*?\s(?P<lvl>INFO|WARNING|ERROR)")

def parse_log_levels(text: str):
    c = {"INFO":0,"WARNING":0,"ERROR":0}
    for m in LOG_LINE.finditer(text):
        c[m.group("lvl")] += 1
    return c

# ---------- ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ----------
CTX_LINE = re.compile(
    r"^\[(?P<ts>\d{9,})\]\s+\((?P<role>user|system|assistant)\)\s*(?:\[(?P<topic>.*?)\])?\s*(?P<content>.*?)(?:\s*\|\s*tags=(?P<tags>.*))?$"
)

def parse_context_block(block: str):
    rows = []
    for raw in block.splitlines():
        raw = raw.strip()
        if not raw or raw.startswith(("<<", ">>")):
            continue
        m = CTX_LINE.match(raw)
        if not m:
            continue
        ts = int(m.group("ts"))
        try:
            tstr = datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
        except Exception:
            tstr = str(ts)
        rows.append({
            "time": tstr,
            "role": m.group("role"),
            "topic": m.group("topic") or "",
            "content": (m.group("content") or "").strip(),
            "tags": (m.group("tags") or "").strip(),
        })
    return pd.DataFrame(rows)

def load_context_df():
    hc = load_json_safe(LOGS / "hot_context.json")
    block = hc.get("context_block", "")
    return parse_context_block(block)

# ---------- ë Œë”ë§ ----------
def _role_badge(role: str):
    cls = "role-user"
    if role == "assistant": cls = "role-assistant"
    elif role == "system": cls = "role-system"
    return f'<span class="role-badge {cls}">{role}</span>'

def render_chat_stream(df, q: str = ""):
    if df.empty:
        st.info("í‘œì‹œí•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    if q:
        mask = df["content"].str.contains(q, case=False, regex=False) | df["tags"].str.contains(q, case=False, regex=False)
        df = df[mask]
    for _, r in df.iterrows():
        st.markdown(
            f'''
            <div class="chat-item">
              {_role_badge(r["role"])}
              <span class="mono" style="opacity:.7">{r["time"]}</span>
              {'<span class="mono" style="margin-left:8px;opacity:.7">['+r["topic"]+']</span>' if r["topic"] else ''}
              <div style="margin-top:6px;white-space:pre-wrap">{st._escape_markdown(r["content"])}</div>
              {('<div class="mono" style="margin-top:6px;opacity:.6">tags: '+st._escape_markdown(r["tags"])+'</div>') if r["tags"] else ''}
            </div>
            ''',
            unsafe_allow_html=True
        )

def render_log_tail(path: Path, tail_n: int, q: str = ""):
    txt = read_text(path, tail_lines=tail_n)
    if q:
        pattern = re.compile(re.escape(q), re.IGNORECASE)
        def _hl(line: str):
            return pattern.sub(lambda m: f"<mark>{m.group(0)}</mark>", line)
        txt = "\n".join(_hl(l) for l in txt.splitlines())
    txt = txt.replace(" ERROR ", ' <span class="log-error">ERROR</span> ') \
             .replace(" WARNING ", ' <span class="log-warn">WARNING</span> ') \
             .replace(" INFO ", ' <span class="log-info">INFO</span> ')
    st.markdown(f'<div class="mono" style="font-size:13px; line-height:1.35; white-space:pre-wrap">{txt}</div>', unsafe_allow_html=True)

# ---------- ìš”ì•½ ì¹´ë“œ ----------
def summary_cards(app_log: Path, show_cols=3):
    txt = read_text(app_log, tail_lines=2000)
    lv = parse_log_levels(txt)
    col = st.columns(show_cols)
    with col[0]: st.metric("ìµœê·¼ INFO",   lv["INFO"])
    with col[1]: st.metric("ìµœê·¼ WARNING",lv["WARNING"])
    with col[2]: st.metric("ìµœê·¼ ERROR",  lv["ERROR"])
    if lv["ERROR"] > 0:
        st.error("ìµœê·¼ ë¡œê·¸ì— ERRORê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ============== [NEW] ì‹¤ì‹œê°„ ëŒ€í™” ë·° ==============

import json, glob, time, pathlib
from datetime import datetime
import streamlit as st
import pandas as pd

# ============== [NEW] ë°ì´í„° ì •ê·œí™” ìœ í‹¸ë¦¬í‹° ==============

POSSIBLE_ROLE_KEYS    = ("role", "author", "speaker", "who")
POSSIBLE_TEXT_KEYS    = ("content", "text", "message", "body")
POSSIBLE_TIME_KEYS    = ("ts", "time", "timestamp", "created_at")
POSSIBLE_SESSION_KEYS = ("session", "session_id", "sid")

def _to_dt(v):
    # ìˆ«ì(epoch)Â·ë¬¸ì ëª¨ë‘ í—ˆìš©
    try:
        if isinstance(v, (int, float)):
            return datetime.fromtimestamp(float(v))
        v = str(v)
        # ISO-like
        return datetime.fromisoformat(v.replace("Z","+00:00"))
    except Exception:
        return None

def normalize_record(raw: dict, src_path: str) -> dict:
    # role
    role = next((raw.get(k) for k in POSSIBLE_ROLE_KEYS if k in raw and raw.get(k)), None)
    if not role:
        # ì´ë²¤íŠ¸/ë©”ëª¨ë¦¬ ë¼ì¸ì—ëŠ” roleì´ ì—†ëŠ” ê²½ìš°ê°€ ë§ìŒ â†’ ê¸°ë³¸ê°’ ë¶€ì—¬
        t = (raw.get("type") or "").lower()
        if "assistant" in t:
            role = "assistant"
        elif "user" in t:
            role = "user"
        else:
            role = "system"
    role = str(role).lower()

    # content
    content = next((raw.get(k) for k in POSSIBLE_TEXT_KEYS if k in raw and raw.get(k)), None)
    if content is None:
        # ë§ˆì§€ë§‰ ë³´ë£¨: ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆê²Œ ìš”ì•½
        content = raw.get("summary") or raw.get("event") or json.dumps(raw, ensure_ascii=False)[:2000]

    # timestamp
    ts = next((raw.get(k) for k in POSSIBLE_TIME_KEYS if k in raw and raw.get(k) is not None), None)
    ts = _to_dt(ts) or datetime.now()

    # session id
    session = next((raw.get(k) for k in POSSIBLE_SESSION_KEYS if k in raw and raw.get(k)), None)
    if not session:
        session = Path(src_path).stem  # íŒŒì¼ëª…ìœ¼ë¡œ ëŒ€ì²´

    return {
        "role": role,
        "content": content,
        "ts": ts,
        "session": session,
        "_src": src_path,
    }

# ì‹¤ì‹œê°„ ìˆ˜ì§‘ ëŒ€ìƒ íŒ¨í„´ (í•„ìš”ì‹œ ê²½ë¡œ ë§ì¶° ì¡°ì •)
CHAT_GLOBS = [
    r"C:\giwanos\data\sessions\*.json",      # ì„¸ì…˜ ëŒ€í™”
    r"C:\giwanos\data\memory\*buffer*.jsonl",# ì‹¤ì‹œê°„ ë²„í¼
    r"C:\giwanos\data\memory\tasks_*.jsonl", # ì‘ì—… íˆìŠ¤í† ë¦¬
    r"C:\giwanos\data\logs\chat_*.jsonl",    # ì„ íƒ: ì±„íŒ… ë¡œê·¸ê°€ ë”°ë¡œ ìˆì„ ë•Œ
]

def _find_chat_files() -> list[pathlib.Path]:
    files = []
    for pattern in CHAT_GLOBS:
        files += [pathlib.Path(p) for p in glob.glob(pattern)]
    # ìµœê·¼ ê²ƒë¶€í„°
    return sorted(files, key=lambda p: p.stat().st_mtime, reverse=True)

def load_records():
    """ì™„ì „í•œ ë°ì´í„° ë¡œë”© ì‹œìŠ¤í…œ - JSON/JSONL ëª¨ë‘ ì§€ì›"""
    rows = []
    for pattern in CHAT_GLOBS:
        for p in glob.glob(pattern):
            suffix = Path(p).suffix.lower()
            try:
                if suffix == ".jsonl":
                    with open(p, "r", encoding="utf-8") as f:
                        for line in f:
                            if not line.strip():
                                continue
                            raw = json.loads(line)
                            rows.append(normalize_record(raw, p))
                else:  # .json
                    with open(p, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    # ì„¸ì…˜ íŒŒì¼ì´ ë°°ì—´/ë”•ì…”ë„ˆë¦¬ ëª¨ë‘ ê°€ëŠ¥
                    if isinstance(data, list):
                        for raw in data:
                            rows.append(normalize_record(raw, p))
                    elif isinstance(data, dict):
                        # common í˜•íƒœ: {"messages":[...]} í˜¹ì€ {"history":[...]}
                        seq = data.get("messages") or data.get("history") or []
                        if isinstance(seq, list) and seq:
                            for raw in seq:
                                rows.append(normalize_record(raw, p))
                        else:  # ëª¨ë¥´ëŠ” êµ¬ì¡° â†’ í•œ ë©ì–´ë¦¬ë¼ë„ normalize
                            rows.append(normalize_record(data, p))
            except Exception as e:
                # íŒŒì¼ í•˜ë‚˜ê°€ ë§ê°€ì ¸ë„ ì „ì²´ëŠ” ê³„ì†
                rows.append(normalize_record({"type":"parse_error","message":str(e)}, p))

    df = pd.DataFrame(rows)
    # ì»¬ëŸ¼ ê°•ì œ ë³´ì • (ì—†ì–´ë„ ì—ëŸ¬ ì•ˆ ë‚˜ê²Œ)
    for c in ["role", "content", "ts", "session", "_src"]:
        if c not in df.columns:
            df[c] = ""
    if not df.empty:
        # ì •ë ¬ ê¸°ë³¸: ì‹œê°„ ì˜¤ë¦„ì°¨ìˆœ
        df = df.sort_values("ts").reset_index(drop=True)
    return df

def _load_messages(files: list[pathlib.Path], since_ts: float | None = None, limit: int = 500):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    df = load_records()

    # í•„í„°ë§ ì ìš©
    if since_ts and not df.empty:
        df = df[df["ts"] >= since_ts]

    # ì œí•œ ì ìš©
    if len(df) > limit:
        df = df.tail(limit)

    return df

def render_balloon(row):
    mine = row["role"] in ("user","system")  # ì™¼/ì˜¤ë¥¸ìª½ ê¸°ì¤€ ì›í•˜ëŠ” ëŒ€ë¡œ
    align = "flex-end" if mine else "flex-start"
    bg = "#0ea5e9" if mine else "#334155"
    txt = str(row["content"]).replace("\n","<br>")
    st.markdown(
        f"""
        <div style="display:flex; justify-content:{align}; margin:4px 0;">
          <div style="max-width:70%; padding:10px 12px; border-radius:12px;
                      background:{bg}; color:white; font-size:14px;">
            <div style="opacity:.8; font-size:12px; margin-bottom:2px;">
                [{row['ts']}] {row['role']}
            </div>
            {txt}
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )


def _chat_bubble(role: str, text: str):
    if role.lower().startswith("user"):
        with st.chat_message("user"):
            st.markdown(text)
    else:
        with st.chat_message("assistant"):
            st.markdown(text)

def page_live():
    st.header("ğŸ”´ ì‹¤ì‹œê°„ ëŒ€í™” ëª¨ë‹ˆí„°")

    # ì»¨íŠ¸ë¡¤ UI
    col1, col2, col3, col4 = st.columns([1,1,1,1])
    with col1:
        refresh = st.slider("ìƒˆë¡œê³ ì¹¨ ì£¼ê¸°(ì´ˆ)", 3, 60, 10, 1)
    with col2:
        show_last = st.selectbox("í‘œì‹œ ë²”ìœ„", ["ìµœê·¼ 100ê°œ", "ìµœê·¼ 300ê°œ", "ìµœê·¼ 500ê°œ"])
        limit = int(show_last.split()[1][:-1])
    with col3:
        role_filter = st.multiselect("ì—­í•  í•„í„°", ["user", "assistant"], default=["user","assistant"])
    with col4:
        kw = st.text_input("í‚¤ì›Œë“œ í¬í•¨", value="")

    # ë°ì´í„° ë¡œë”©
    df = load_records()
    if df.empty:
        st.warning("ëŒ€í™” ë¡œê·¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. `sessions/` ë˜ëŠ” `memory/*jsonl` ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # ì—­í•  í•„í„°ê°€ ìˆì–´ë„, ì»¬ëŸ¼ ì—†ìœ¼ë©´ ì£½ì§€ ì•Šë„ë¡ ê°€ë“œ
    if "role" in df.columns and role_filter:
        df = df[df["role"].str.lower().isin([r.lower() for r in role_filter])]

    # í‚¤ì›Œë“œ í•„í„°ë§
    if kw and "content" in df.columns:
        df = df[df["content"].str.contains(kw, case=False, na=False)]

    # ì œí•œ ì ìš©
    if len(df) > limit:
        df = df.tail(limit)

    # ìƒë‹¨ ìš”ì•½
    meta = st.container()
    with meta:
        left, mid, right = st.columns([1,2,1])
        with left:
            st.metric("ë¡œë“œëœ ë©”ì‹œì§€", len(df))
        with mid:
            st.caption("ë°ì´í„° ì†ŒìŠ¤:  \n" + "\n".join([f"- `{p}`" for p in CHAT_GLOBS[:3]]))
        with right:
            if st.button("ìƒˆë¡œê³ ì¹¨", use_container_width=True):
                st.experimental_rerun()

    st.divider()

    # ë©”ì‹œì§€ ë Œë”ë§
    if df.empty:
        st.info("í‘œì‹œí•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for _, r in df.iterrows():
            render_balloon(r)

    st.divider()
    # í•˜ë‹¨ ë°”: ìë™ ìƒˆë¡œê³ ì¹¨
    st.caption("ìë™ ìƒˆë¡œê³ ì¹¨ ë™ì‘ ì¤‘â€¦")
    st.experimental_rerun() if st.autorefresh(interval=refresh * 1000, key="live_ref") else None

ROOT = Path(os.getenv("VELOS_ROOT", "C:/giwanos"))
DATA = ROOT / "data"
REPORTS = DATA / "reports" / "auto"
DISPATCH = DATA / "reports" / "_dispatch"
LOGS = DATA / "logs"
SESSION = DATA / "session"
MEMORY = DATA / "memory"


def resolve_report_key(key: str):
    # key ì˜ˆ: 20250816_150544
    pdf = next(REPORTS.glob(f"velos_auto_report_{key}_*_ko.pdf"), None) or \
          next(REPORTS.glob(f"velos_auto_report_{key}_ko.pdf"), None)
    dispatch = list(DISPATCH.glob(f"dispatch_{key[:8]}*.json"))
    return {"pdf": pdf, "dispatch": dispatch}


def load_json_safe(p: Path):
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return {}


def notion_page_url_from_dispatch(d: dict):
    # dispatch JSONì— page_url ì €ì¥ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
    for k in ("notion", "Notion", "page", "page_url", "NOTION_PAGE_URL"):
        if k in d and isinstance(d[k], str) and d[k].startswith("http"):
            return d[k]
    for k in ("page_url", "notion_page_url"):
        if k in d.get("meta", {}):
            return d["meta"][k]
    return None


def slack_permalink_from_dispatch(d: dict):
    for k in ("slack", "Slack", "SLACK_MESSAGE_URL", "slack_url"):
        v = d.get(k)
        if isinstance(v, str) and v.startswith("http"):
            return v
        if isinstance(v, dict):
            for kk in ("permalink", "url", "message_url"):
                if isinstance(v.get(kk), str) and v[kk].startswith("http"):
                    return v[kk]
    return None


def tail_file(path: Path, n=200):
    if not path.exists():
        return []
    lines = path.read_text(encoding="utf-8", errors="ignore").splitlines()
    return lines[-n:]


# --- ì‹¤ì‹œê°„ tailer (íŒŒì¼ ë³€ê²½ ê°ì§€) ---
class FileTailStreamer:
    def __init__(self, path: Path, poll_sec: float = 1.0, max_lines=1000):
        self.path = path
        self.poll = poll_sec
        self.max_lines = max_lines
        self._stop = threading.Event()
        self._q = queue.Queue()

    def start(self):
        t = threading.Thread(target=self._run, daemon=True)
        t.start()
        return self

    def stop(self):
        self._stop.set()

    def _run(self):
        last_size = -1
        buf = []
        while not self._stop.is_set():
            try:
                if self.path.exists():
                    now_size = self.path.stat().st_size
                    if now_size != last_size:
                        last_size = now_size
                        buf = tail_file(self.path, self.max_lines)
                        self._q.put(buf)
                time.sleep(self.poll)
            except Exception:
                time.sleep(self.poll)

    def get_latest(self, timeout=0.0):
        try:
            return self._q.get(timeout=timeout)
        except queue.Empty:
            return None


def main():
    st.write(":green[boot] ëŒ€ì‹œë³´ë“œ ì´ˆê¸°í™”â€¦")  # ì²« í”„ë ˆì„ ê°•ì œ

    # CSS ìŠ¤íƒ€ì¼ ì£¼ì…
    _inject_base_css()

    # -------- ì‚¬ì´ë“œë°”: ì œì–´/í•„í„° --------
    st.sidebar.header("ğŸ” ê²€ìƒ‰ ì˜µì…˜")

    # ê¸°ë³¸ ê²½ë¡œ í‘œì‹œ
    default_paths = [
        str(REPORTS),
        str(LOGS),
        str(MEMORY),
        str(SESSION),
        str(DATA / "snapshots"),
        str(DISPATCH),
    ]

    st.sidebar.markdown("**ê²€ìƒ‰ ê²½ë¡œ**")
    for p in default_paths:
        st.sidebar.code(p)

    # ì‹¤ì‹œê°„ ìƒˆë¡œê³ ì¹¨ ì˜µì…˜
    auto_refresh = st.sidebar.checkbox("ğŸ”„ ì‹¤ì‹œê°„ ìƒˆë¡œê³ ì¹¨ (30ì´ˆ)", value=False)
    if auto_refresh:
        time.sleep(0.1)  # ì§§ì€ ì§€ì—°ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨ íš¨ê³¼

    # -------- ë©”ì¸ ëŒ€ì‹œë³´ë“œ --------
    st.title("ğŸ›°ï¸ VELOS ëª¨ë‹ˆí„° ëŒ€ì‹œë³´ë“œ")

    # ì‹œìŠ¤í…œ ìš”ì•½ ì¹´ë“œ
    app_log = LOGS / "velos_bridge.log"
    if app_log.exists():
        summary_cards(app_log)

    tab_report, tab_dispatch, tab_logs, tab_memory, tab_live = st.tabs(
        ["ë³´ê³ ì„œ","ë””ìŠ¤íŒ¨ì²˜","ë¡œê·¸","ë©”ëª¨ë¦¬","ì‹¤ì‹œê°„"]
    )

    with tab_report:
        st.subheader("ğŸ“Š ìë™ ë³´ê³ ì„œ")

        # ìµœê·¼ ë³´ê³ ì„œ íŒŒì¼ë“¤
        report_files = list(REPORTS.glob("*.pdf")) + list(REPORTS.glob("*.md"))
        report_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

        if report_files:
            st.success(f"ì´ {len(report_files)}ê°œì˜ ë³´ê³ ì„œ íŒŒì¼ ë°œê²¬")

            # ìµœê·¼ 10ê°œ í‘œì‹œ
            for i, report_file in enumerate(report_files[:10]):
                with st.expander(f"{report_file.name} ({time.ctime(report_file.stat().st_mtime)})"):
                    if report_file.suffix == '.md':
                        try:
                            content = report_file.read_text(encoding='utf-8')
                            st.text_area("ë‚´ìš©", content, height=200, key=f"report_{i}")
                        except Exception as e:
                            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                    else:
                        st.info(f"PDF íŒŒì¼: {report_file.name}")
                        # PDF ë‹¤ìš´ë¡œë“œ ë§í¬
                        st.markdown(f"[ğŸ“¥ ë‹¤ìš´ë¡œë“œ]({report_file.as_uri()})")
        else:
            st.warning("ë³´ê³ ì„œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    with tab_dispatch:
        st.subheader("ğŸ“‹ ë””ìŠ¤íŒ¨ì¹˜ ë¡œê·¸")

        # ë””ìŠ¤íŒ¨ì¹˜ íŒŒì¼ë“¤
        dispatch_files = list(DISPATCH.glob("*.json"))
        dispatch_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

        if dispatch_files:
            st.success(f"ì´ {len(dispatch_files)}ê°œì˜ ë””ìŠ¤íŒ¨ì¹˜ íŒŒì¼ ë°œê²¬")

            # ìµœê·¼ 5ê°œ í‘œì‹œ
            for i, dispatch_file in enumerate(dispatch_files[:5]):
                with st.expander(f"{dispatch_file.name} ({time.ctime(dispatch_file.stat().st_mtime)})"):
                    try:
                        data = load_json_safe(dispatch_file)
                        st.json(data)

                        # Notion/Slack ë§í¬ í‘œì‹œ
                        notion_url = notion_page_url_from_dispatch(data)
                        slack_url = slack_permalink_from_dispatch(data)

                        if notion_url:
                            st.markdown(f"[ğŸ“ Notion í˜ì´ì§€]({notion_url})")
                        if slack_url:
                            st.markdown(f"[ğŸ’¬ Slack ë©”ì‹œì§€]({slack_url})")
                    except Exception as e:
                        st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        else:
            st.warning("ë””ìŠ¤íŒ¨ì¹˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    with tab_logs:
        st.subheader("ğŸ“ ì‹œìŠ¤í…œ ë¡œê·¸")

        # ë¡œê·¸ íŒŒì¼ë“¤
        log_files = list(LOGS.glob("*.log")) + list(LOGS.glob("*.txt"))
        log_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

        if log_files:
            st.success(f"ì´ {len(log_files)}ê°œì˜ ë¡œê·¸ íŒŒì¼ ë°œê²¬")

            # ë¡œê·¸ íŒŒì¼ ì„ íƒ
            selected_log = st.selectbox("ë¡œê·¸ íŒŒì¼ ì„ íƒ", [f.name for f in log_files])

            if selected_log:
                log_file = next(f for f in log_files if f.name == selected_log)

                # ë¡œê·¸ ê²€ìƒ‰ í•„í„°
                log_search = st.text_input("ğŸ” ë¡œê·¸ ë‚´ìš© ê²€ìƒ‰", placeholder="ë¡œê·¸ì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œ...")

                # í‘œì‹œí•  ì¤„ ìˆ˜
                tail_lines = st.slider("í‘œì‹œí•  ì¤„ ìˆ˜", 50, 500, 200, step=50)

                try:
                    # ìƒˆë¡œìš´ ë Œë”ë§ í•¨ìˆ˜ ì‚¬ìš©
                    render_log_tail(log_file, tail_lines, log_search)
                except Exception as e:
                    st.error(f"ë¡œê·¸ ì½ê¸° ì˜¤ë¥˜: {e}")
        else:
            st.warning("ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    with tab_memory:
        st.subheader("ğŸ’¾ ë©”ëª¨ë¦¬ ìƒíƒœ")

        # ë©”ëª¨ë¦¬ íŒŒì¼ë“¤
        memory_files = list(MEMORY.glob("*.json")) + list(MEMORY.glob("*.jsonl"))
        memory_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

        if memory_files:
            st.success(f"ì´ {len(memory_files)}ê°œì˜ ë©”ëª¨ë¦¬ íŒŒì¼ ë°œê²¬")

            # ë©”ëª¨ë¦¬ íŒŒì¼ ì„ íƒ
            selected_memory = st.selectbox("ë©”ëª¨ë¦¬ íŒŒì¼ ì„ íƒ", [f.name for f in memory_files])

            if selected_memory:
                memory_file = next(f for f in memory_files if f.name == selected_memory)
                try:
                    if memory_file.suffix == '.json':
                        data = load_json_safe(memory_file)
                        st.json(data)
                    else:  # .jsonl
                        lines = tail_file(memory_file, 50)
                        st.text_area("ìµœê·¼ ë©”ëª¨ë¦¬ í•­ëª©", "\n".join(lines), height=400)
                except Exception as e:
                    st.error(f"ë©”ëª¨ë¦¬ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        else:
            st.warning("ë©”ëª¨ë¦¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    with tab_live:
        page_live()

    # -------- í‘¸í„° --------
    st.markdown("---")
    st.caption(f"VELOS ROOT: {ROOT} â€¢ ë§ˆì§€ë§‰ ê°±ì‹ : {time.strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error("ë Œë”ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        st.exception(e)   # í™”ë©´ì— ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤ í‘œì‹œ
        raise
