"""
##############################################################
# VELOS OPERATION DECLARATION
# â–¶ íŒŒì¼ëª… : velos_rag_poc.py      (âš  ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€)
# â–¶ ê²½   ë¡œ : C:/giwanos/scripts/
# â–¶ ëª©   ì  : Qdrant + LangChain ê¸°ë°˜ â€œìë™ ê¸°ì–µ íšŒìˆ˜â€ PoC
# â–¶ ìš”   ì•½ : ì™¸ë¶€ ì €ì¥ëœ ë¬¸ì„œë¥¼ ì„ë² ë”©â†’ì €ì¥â†’ê²€ìƒ‰â†’LLM í”„ë¡¬í”„íŠ¸
#              ë¡œ ì£¼ì…í•˜ëŠ” ì™„ì „ ìë™ RAG íŒŒì´í”„ë¼ì¸ì„ ê²€ì¦í•œë‹¤.
# â–¶ í•µì‹¬ ê·œì¹™
#   1) íŒŒì¼ëª…Â·ê²½ë¡œ ê³ ì •   2) ì‹¤í–‰ ì „Â·í›„ ìì²´ ê²€ì¦ í•„ìˆ˜
#   3) ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë¡œê¹… í›„ ì¢…ë£Œ
##############################################################
"""

import os, sys, json, time, logging
from typing import List, Dict

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘  ê²½ë¡œ ì…‹ì—… (ëª¨ë“ˆ ì¶©ëŒ ë°©ì§€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT_DIR = r"C:/giwanos"
sys.path.append(ROOT_DIR)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘¡ ë¡œê¹… ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_PATH = os.path.join(ROOT_DIR, "data", "logs", "rag_poc_log.txt")
os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)
logging.basicConfig(level=logging.INFO,
                    format="%(asctime)s | %(levelname)s | %(message)s",
                    handlers=[logging.FileHandler(LOG_PATH, encoding="utf-8"),
                              logging.StreamHandler(sys.stdout)])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘¢ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from qdrant_client import QdrantClient
    from langchain.embeddings import HuggingFaceEmbeddings
    from langchain.vectorstores import Qdrant as LC_Qdrant
    from langchain.memory import ConversationVectorStoreTokenBufferMemory
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import ConversationalRetrievalChain
except ImportError as e:
    logging.error("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. requirements_rag.txt ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.")
    raise e

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘£ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
QDRANT_URL = os.getenv("VEL_QDRANT_URL", "http://127.0.0.1:6333")
COLLECTION = "velos-memory"
EMBED_MODEL = "jhgan/ko-sbert-sts"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘¤ ì´ˆê¸°í™” í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_vector_store():
    client = QdrantClient(url=QDRANT_URL)
    embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)
    vs = LC_Qdrant(client=client,
                   collection_name=COLLECTION,
                   embeddings=embeddings)
    return vs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘¥ ìì²´ ê²€ì¦ ë£¨í‹´
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def self_validate(vs):
    """
    1) ë”ë¯¸ ë¬¸ì„œ 2ê°œ upsert
    2) ì¿¼ë¦¬ë¡œ íšŒìˆ˜ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
    """
    docs = [
        {"id": "mem1", "text": "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ê²€ìƒ‰ ê°•í™” ìƒì„±(RAG)ì˜ í•µì‹¬ì´ë‹¤."},
        {"id": "mem2", "text": "VELOS ì‹œìŠ¤í…œì€ GPT-4o ê¸°ë°˜ ê³ ë„í™” AI ìš´ì˜ í”Œë«í¼ì´ë‹¤."}
    ]
    # upsert
    for d in docs:
        vs.add_texts(texts=[d["text"]], metadatas=[{"source": d["id"]}])

    # ê²€ìƒ‰
    hits = vs.similarity_search("RAG íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬ì€ ë²¡í„° DBì…ë‹ˆë‹¤.", k=2)
    assert len(hits) >= 1, "ìì²´ ê²€ì¦ ì‹¤íŒ¨: ìœ ì‚¬ ë¬¸ì„œ íšŒìˆ˜ê°€ 0ê°œì…ë‹ˆë‹¤."
    logging.info("âœ… ìì²´ ê²€ì¦ í†µê³¼ - ìœ ì‚¬ ë¬¸ì„œ %dê°œ íšŒìˆ˜", len(hits))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘¦ ëŒ€í™” ë£¨í”„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_chat(vs):
    memory = ConversationVectorStoreTokenBufferMemory(
        vectorstore=vs,
        k=6,
        max_token_limit=2000,
    )
    llm = ChatOpenAI(model_name="gpt-4o-mini",
                     temperature=0.2,
                     request_timeout=30)
    rag_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vs.as_retriever(search_kwargs={"k": 6}),
        memory=memory,
    )
    logging.info("ğŸš€ Velos RAG PoC ëŒ€í™” ë£¨í”„ ì‹œì‘ (ì¢…ë£Œ: Ctrl+C)")
    while True:
        try:
            question = input("YOU> ").strip()
            if not question:
                continue
            start = time.time()
            answer = rag_chain({"question": question})["answer"]
            elapsed = time.time() - start
            print(f"VEL> {answer}\n   (latency {elapsed*1000:.1f} ms)\n")
        except KeyboardInterrupt:
            print("\n[ì¢…ë£Œ ìš”ì²­] ì•ˆë…•íˆ ê°€ì„¸ìš”.")
            break
        except Exception as e:
            logging.exception("ëŒ€í™” ë£¨í”„ ì˜¤ë¥˜: %s", e)
            print("âš  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â‘§ ë©”ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    try:
        vectordb = init_vector_store()
        self_validate(vectordb)
        run_chat(vectordb)
    except Exception:
        logging.exception("PoC ì „ì²´ ì‹¤íŒ¨ â€“ ì„¸ë¶€ ë¡œê·¸ ì°¸ì¡°")
        sys.exit(1)
