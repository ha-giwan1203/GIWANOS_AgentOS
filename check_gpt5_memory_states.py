#!/usr/bin/env python3
"""
GPT-5 ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sqlite3
import json
from pathlib import Path
from datetime import datetime

def check_gpt5_memory_states():
    """GPT-5 ëª¨ë‹ˆí„°ë§ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸"""
    
    gpt5_db_path = Path("/home/user/webapp/data/gpt5_monitor/gpt5_monitor.db")
    
    if not gpt5_db_path.exists():
        print(f"âŒ GPT-5 ëª¨ë‹ˆí„°ë§ DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {gpt5_db_path}")
        return
    
    print(f"ğŸ” GPT-5 ë©”ëª¨ë¦¬ ìƒíƒœ ë¶„ì„ ì¤‘: {gpt5_db_path}")
    print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {gpt5_db_path.stat().st_size:,} bytes")
    
    try:
        with sqlite3.connect(str(gpt5_db_path)) as conn:
            cursor = conn.cursor()
            
            # í…Œì´ë¸” ëª©ë¡ í™•ì¸
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            print(f"\nğŸ“‹ í…Œì´ë¸” ëª©ë¡: {tables}")
            
            for table_name in tables:
                print(f"\nğŸ—‚ï¸ í…Œì´ë¸”: {table_name}")
                
                # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ í™•ì¸
                cursor.execute(f"PRAGMA table_info({table_name})")
                schema = cursor.fetchall()
                columns = [col[1] for col in schema]
                print(f"   ì»¬ëŸ¼: {columns}")
                
                # ë ˆì½”ë“œ ìˆ˜ í™•ì¸
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                count = cursor.fetchone()[0]
                print(f"   ë ˆì½”ë“œ ìˆ˜: {count:,}ê°œ")
                
                # memory_states í…Œì´ë¸” íŠ¹ë³„ ë¶„ì„
                if table_name == 'memory_states':
                    print(f"\nğŸ§  ë©”ëª¨ë¦¬ ìƒíƒœ ìƒì„¸ ë¶„ì„:")
                    cursor.execute(f"SELECT * FROM {table_name} ORDER BY timestamp DESC LIMIT 10")
                    memory_states = cursor.fetchall()
                    
                    for i, state in enumerate(memory_states, 1):
                        state_dict = dict(zip(columns, state))
                        print(f"   {i}. ì„¸ì…˜: {state_dict.get('session_id', 'N/A')}")
                        print(f"      ì‹œê°„: {state_dict.get('timestamp', 'N/A')}")
                        print(f"      ë‹¨ê¸° ë©”ëª¨ë¦¬: {state_dict.get('short_term_usage', 'N/A')}%")
                        print(f"      ì¥ê¸° ë©”ëª¨ë¦¬: {state_dict.get('long_term_usage', 'N/A')}%")
                        print(f"      ë²„í¼ ì‚¬ìš©ëŸ‰: {state_dict.get('buffer_usage', 'N/A')}%")
                        if state_dict.get('context_summary'):
                            summary_preview = str(state_dict['context_summary'])[:50] + "..." if len(str(state_dict['context_summary'])) > 50 else str(state_dict['context_summary'])
                            print(f"      ì»¨í…ìŠ¤íŠ¸: {summary_preview}")
                        print()
                
                # conversation_messages í…Œì´ë¸”ì—ì„œ í•™ìŠµ ê´€ë ¨ ë©”ì‹œì§€ ê²€ìƒ‰
                elif table_name == 'conversation_messages':
                    print(f"\nğŸ’¬ í•™ìŠµ ê´€ë ¨ ëŒ€í™” ë©”ì‹œì§€:")
                    cursor.execute(f"""
                        SELECT * FROM {table_name} 
                        WHERE content LIKE '%í•™ìŠµ%' OR content LIKE '%learning%' 
                        OR content LIKE '%memory%' OR content LIKE '%ê¸°ì–µ%'
                        ORDER BY timestamp DESC LIMIT 5
                    """)
                    learning_messages = cursor.fetchall()
                    
                    for i, msg in enumerate(learning_messages, 1):
                        msg_dict = dict(zip(columns, msg))
                        print(f"   {i}. íƒ€ì…: {msg_dict.get('message_type', 'N/A')}")
                        print(f"      ì‹œê°„: {msg_dict.get('timestamp', 'N/A')}")
                        content_preview = str(msg_dict.get('content', ''))[:100] + "..." if len(str(msg_dict.get('content', ''))) > 100 else str(msg_dict.get('content', ''))
                        print(f"      ë‚´ìš©: {content_preview}")
                        print()
                
                # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ (ì²˜ìŒ 3ê°œ)
                if count > 0 and table_name not in ['memory_states', 'conversation_messages']:
                    cursor.execute(f"SELECT * FROM {table_name} LIMIT 3")
                    samples = cursor.fetchall()
                    print(f"   ìƒ˜í”Œ ë°ì´í„°:")
                    for i, sample in enumerate(samples, 1):
                        sample_dict = dict(zip(columns, sample))
                        print(f"   {i}. {sample_dict}")
                    print()
    
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {e}")

def check_learning_memory_content():
    """learning_memory.jsonì˜ ì‹¤ì œ í•™ìŠµ ë‚´ìš© í™•ì¸"""
    
    learning_json_path = Path("/home/user/webapp/data/memory/learning_memory.json")
    
    if not learning_json_path.exists():
        print(f"âŒ í•™ìŠµ ë©”ëª¨ë¦¬ JSON íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {learning_json_path}")
        return
    
    print(f"\nğŸ“š í•™ìŠµ ë©”ëª¨ë¦¬ JSON ë‚´ìš© ë¶„ì„:")
    
    try:
        with open(learning_json_path, 'r', encoding='utf-8') as f:
            learning_data = json.load(f)
        
        if isinstance(learning_data, list):
            print(f"   ì „ì²´ í•™ìŠµ ê¸°ë¡: {len(learning_data):,}ê°œ")
            
            # ìµœê·¼ í•™ìŠµ ê¸°ë¡ ëª‡ ê°œ í‘œì‹œ
            print(f"\nğŸ“ ìµœê·¼ í•™ìŠµ ê¸°ë¡ ìƒ˜í”Œ:")
            for i, record in enumerate(learning_data[-5:], 1):  # ë§ˆì§€ë§‰ 5ê°œ
                if isinstance(record, dict):
                    timestamp = record.get('timestamp', 'N/A')
                    content = record.get('content', record.get('insight', str(record)))
                    content_preview = str(content)[:100] + "..." if len(str(content)) > 100 else str(content)
                    print(f"   {i}. [{timestamp}] {content_preview}")
            
            # í•™ìŠµ í‚¤ì›Œë“œë¡œ í•„í„°ë§
            learning_keywords = ['í•™ìŠµ', 'learning', 'train', 'memory', 'ê¸°ì–µ', 'GPT', 'AI']
            relevant_records = []
            
            for record in learning_data:
                if isinstance(record, dict):
                    record_str = json.dumps(record, ensure_ascii=False).lower()
                    if any(keyword.lower() in record_str for keyword in learning_keywords):
                        relevant_records.append(record)
            
            print(f"\nğŸ” í•™ìŠµ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ê¸°ë¡: {len(relevant_records)}ê°œ")
            for i, record in enumerate(relevant_records[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ
                timestamp = record.get('timestamp', 'N/A')
                content = record.get('content', record.get('insight', str(record)))
                content_preview = str(content)[:150] + "..." if len(str(content)) > 150 else str(content)
                print(f"   {i}. [{timestamp}] {content_preview}")
        
        else:
            print(f"   ë°ì´í„° í˜•íƒœ: {type(learning_data)}")
            print(f"   ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {str(learning_data)[:200]}...")
    
    except Exception as e:
        print(f"âŒ í•™ìŠµ ë©”ëª¨ë¦¬ JSON ë¶„ì„ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    print("ğŸš€ VELOS-GPT5 ë©”ëª¨ë¦¬ ìƒíƒœ ìƒì„¸ í™•ì¸")
    print("="*60)
    
    check_gpt5_memory_states()
    check_learning_memory_content()
    
    print(f"\nâœ… ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì™„ë£Œ!")
    print("ğŸ¯ ê²°ë¡ : VELOS-GPT5 ì‹œìŠ¤í…œì€ ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ê³¼ í•™ìŠµ ê¸°ë¡ ì €ì¥ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤!")