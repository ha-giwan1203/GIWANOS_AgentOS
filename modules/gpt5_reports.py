# [ACTIVE] VELOS-GPT5 ë³´ê³ ì„œ ìƒì„± ëª¨ë“ˆ - ìë™ ë³´ê³ ì„œ ìƒì„± ë° ì „ì†¡
import json
import os
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
from jinja2 import Template
import pandas as pd

# í•œêµ­ì‹œê°„ ì„¤ì •
os.environ['TZ'] = 'Asia/Seoul'
time.tzset()

from modules.gpt5_monitor import get_gpt5_monitor
from modules.dashboard_utils import ROOT, DATA


class GPT5ReportGenerator:
    """GPT-5 ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.monitor = get_gpt5_monitor()
        self.templates_path = ROOT / "templates" / "gpt5_reports"
        self.templates_path.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ë³¸ í…œí”Œë¦¿ ìƒì„±
        self._create_default_templates()
    
    def _create_default_templates(self):
        """ê¸°ë³¸ ë³´ê³ ì„œ í…œí”Œë¦¿ ìƒì„±"""
        
        # ì‹¤ì‹œê°„ ìƒíƒœ ë³´ê³ ì„œ í…œí”Œë¦¿
        realtime_template = """
# ğŸ§  VELOS-GPT5 ì‹¤ì‹œê°„ ìƒíƒœ ë³´ê³ ì„œ

**ìƒì„± ì‹œê°„**: {{ timestamp }}
**ë³´ê³  ê¸°ê°„**: ì‹¤ì‹œê°„ ìƒíƒœ

## ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½

### ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
- **CPU ì‚¬ìš©ë¥ **: {{ system.cpu_percent }}%
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: {{ system.memory_percent }}%
- **ë””ìŠ¤í¬ ì—¬ìœ ê³µê°„**: {{ "%.1f"|format(system.disk_free_gb) }}GB

### ğŸ§  GPT-5 ì—°ë™ ìƒíƒœ
- **í™œì„± ì„¸ì…˜**: {{ gpt5.active_sessions }}ê°œ
- **24ì‹œê°„ ì˜¤ë¥˜**: {{ gpt5.errors_24h }}ê±´
- **ëª¨ë‹ˆí„°ë§ ìƒíƒœ**: {{ gpt5.monitoring_status }}

## ğŸ“‹ í™œì„± ì„¸ì…˜ ëª©ë¡

{% if active_sessions %}
| ì„¸ì…˜ ID | ì‹œì‘ ì‹œê°„ | ì§€ì†ì‹œê°„ | ë©”ì‹œì§€ ìˆ˜ | ë§¥ë½ ì ìˆ˜ |
|---------|----------|----------|-----------|-----------|
{% for session in active_sessions -%}
| {{ session.session_id }} | {{ session.start_time.split('.')[0] }} | {{ session.get('duration_formatted', '0ë¶„') }} | {{ session.message_count }} | {{ "%.2f"|format(session.context_score) }} |
{% endfor %}
{% else %}
*í˜„ì¬ í™œì„± ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.*
{% endif %}

## ğŸ¯ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

{% if insights %}
{% for insight in insights %}
- {{ insight }}
{% endfor %}
{% else %}
- ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- ë©”ëª¨ë¦¬ ë° ë§¥ë½ ê´€ë¦¬ê°€ ì•ˆì •ì ì…ë‹ˆë‹¤.
{% endif %}

## âš ï¸ ê¶Œì¥ ì‚¬í•­

{% if recommendations %}
{% for rec in recommendations %}
- {{ rec }}
{% endfor %}
{% else %}
- í˜„ì¬ íŠ¹ë³„í•œ ì¡°ì¹˜ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê³„ì† ìœ ì§€í•˜ì„¸ìš”.
{% endif %}

---
*ì´ ë³´ê³ ì„œëŠ” VELOS-GPT5 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì—ì„œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""
        
        # ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ í…œí”Œë¦¿
        performance_template = """
# ğŸ“Š VELOS-GPT5 ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ

**ìƒì„± ì‹œê°„**: {{ timestamp }}
**ë¶„ì„ ê¸°ê°„**: {{ analysis_period }}

## ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìš”ì•½

### âš¡ ì‘ë‹µ ì„±ëŠ¥
- **í‰ê·  ì‘ë‹µì‹œê°„**: {{ "%.1f"|format(avg_response_time) }}ms
- **ìµœëŒ€ ì‘ë‹µì‹œê°„**: {{ "%.1f"|format(max_response_time) }}ms
- **ì‘ë‹µì‹œê°„ í¸ì°¨**: {{ "%.1f"|format(response_time_std) }}ms

### ğŸ§  ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- **í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {{ "%.1f"|format(avg_memory_usage) }}MB
- **ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {{ "%.1f"|format(max_memory_usage) }}MB
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì ìˆ˜**: {{ "%.2f"|format(memory_efficiency) }}

### ğŸ¯ ë§¥ë½ í’ˆì§ˆ
- **í‰ê·  ì¼ê´€ì„± ì ìˆ˜**: {{ "%.3f"|format(avg_coherence) }}
- **ë§¥ë½ ìœ ì§€ìœ¨**: {{ "%.1f"|format(context_retention) }}%
- **í’ˆì§ˆ ì €í•˜ ìœ„í—˜**: {{ "%.2f"|format(degradation_risk) }}

## ğŸ“Š ìƒì„¸ ë¶„ì„

### ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„
{{ trend_analysis }}

### ğŸ” ë¬¸ì œì  ë° ê°œì„ ì‚¬í•­
{% if issues %}
{% for issue in issues %}
#### {{ issue.type }}
**ì„¤ëª…**: {{ issue.description }}
**ì˜í–¥ë„**: {{ issue.severity }}
**ê¶Œì¥ ì¡°ì¹˜**: {{ issue.recommendation }}

{% endfor %}
{% else %}
*ë¶„ì„ ê¸°ê°„ ë™ì•ˆ íŠ¹ë³„í•œ ë¬¸ì œì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.*
{% endif %}

## ğŸ“‹ ê¶Œì¥ì‚¬í•­

{% for recommendation in recommendations %}
{{ loop.index }}. **{{ recommendation.title }}**
   - {{ recommendation.description }}
   - ìš°ì„ ìˆœìœ„: {{ recommendation.priority }}
   
{% endfor %}

---
*ì´ ë³´ê³ ì„œëŠ” VELOS-GPT5 ì„±ëŠ¥ ë¶„ì„ ì‹œìŠ¤í…œì—ì„œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""
        
        # í…œí”Œë¦¿ íŒŒì¼ ì €ì¥
        templates = {
            'realtime_status.md': realtime_template,
            'performance_analysis.md': performance_template
        }
        
        for filename, content in templates.items():
            template_file = self.templates_path / filename
            if not template_file.exists():
                template_file.write_text(content, encoding='utf-8')
    
    def generate_realtime_report(self) -> Dict:
        """ì‹¤ì‹œê°„ ìƒíƒœ ë³´ê³ ì„œ ìƒì„±"""
        try:
            # ì‹œìŠ¤í…œ ìƒíƒœ ìˆ˜ì§‘
            health = self.monitor.get_system_health()
            active_sessions = self.monitor.get_active_sessions()
            
            # ì„¸ì…˜ ì§€ì†ì‹œê°„ ê³„ì‚° ë° í¬ë§· ê°œì„ 
            for session in active_sessions:
                start_time = datetime.fromisoformat(session['start_time'])
                duration_seconds = (datetime.now() - start_time).total_seconds()
                
                # ì§€ì†ì‹œê°„ì„ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·
                if duration_seconds < 60:
                    session['duration_formatted'] = f"{int(duration_seconds)}ì´ˆ"
                elif duration_seconds < 3600:
                    session['duration_formatted'] = f"{int(duration_seconds // 60)}ë¶„"
                else:
                    hours = int(duration_seconds // 3600)
                    minutes = int((duration_seconds % 3600) // 60)
                    if minutes > 0:
                        session['duration_formatted'] = f"{hours}ì‹œê°„ {minutes}ë¶„"
                    else:
                        session['duration_formatted'] = f"{hours}ì‹œê°„"
                
                session['duration'] = duration_seconds / 3600  # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€
            
            # ëŒ€í™” ìš”ì•½ ìƒì„± (í™œì„± ì„¸ì…˜ë“¤ì— ëŒ€í•´)
            conversation_summaries = []
            for session in active_sessions:
                # ê° ì„¸ì…˜ì— ëŒ€í•œ ì‹¤ì‹œê°„ ìš”ì•½ ìƒì„±
                summary = self.monitor.generate_session_summary(session['session_id'], 'realtime')
                if summary and 'error' not in summary:
                    conversation_summaries.append({
                        'session_id': session['session_id'],
                        'content_summary': summary.get('content_summary', ''),
                        'topic_keywords': json.loads(summary.get('topic_keywords', '[]')),
                        'interaction_pattern': summary.get('interaction_pattern', ''),
                        'quality_metrics': json.loads(summary.get('quality_metrics', '{}')),
                        'message_count': summary.get('message_stats', {}).get('total_messages', 0)
                    })
            
            # ìµœê·¼ ëŒ€í™” ìš”ì•½ë“¤ë„ ì¡°íšŒ
            recent_summaries = self.monitor.get_recent_conversation_summaries(hours=1)
            if recent_summaries:
                conversation_summaries.extend(recent_summaries)
            
            # ì¸ì‚¬ì´íŠ¸ ìƒì„±
            insights = self._generate_insights(health, active_sessions)
            recommendations = self._generate_recommendations(health, active_sessions)
            
            # í…œí”Œë¦¿ ë°ì´í„° ì¤€ë¹„
            template_data = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'system': health.get('system', {}),
                'gpt5': health.get('gpt5', {}),
                'active_sessions': active_sessions,
                'conversation_summaries': conversation_summaries,
                'insights': insights,
                'recommendations': recommendations
            }
            
            # í…œí”Œë¦¿ ë Œë”ë§
            template_file = self.templates_path / 'realtime_status.md'
            template = Template(template_file.read_text(encoding='utf-8'))
            content = template.render(**template_data)
            
            # ë³´ê³ ì„œ ì €ì¥
            report_id = f"realtime_{int(datetime.now().timestamp())}"
            report_file = self.monitor.reports_path / f"{report_id}.md"
            report_file.write_text(content, encoding='utf-8')
            
            return {
                'id': report_id,
                'type': 'realtime_status',
                'file_path': str(report_file),
                'content': content,
                'data': template_data,
                'generated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.monitor.log(f"ì‹¤ì‹œê°„ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}", "ERROR")
            return {}
    
    def generate_performance_report(self, hours: int = 24) -> Dict:
        """ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        try:
            # ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘ (ëª¨ë“  í™œì„± ì„¸ì…˜)
            active_sessions = self.monitor.get_active_sessions()
            performance_data = []
            
            for session in active_sessions:
                session_analytics = self.monitor.get_session_analytics(session['session_id'], hours)
                if session_analytics:
                    performance_data.append(session_analytics)
            
            # í†µê³„ ê³„ì‚°
            stats = self._calculate_performance_stats(performance_data)
            
            # íŠ¸ë Œë“œ ë¶„ì„
            trend_analysis = self._analyze_trends(performance_data)
            
            # ë¬¸ì œì  ì‹ë³„
            issues = self._identify_issues(stats, performance_data)
            
            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self._generate_performance_recommendations(stats, issues)
            
            # í…œí”Œë¦¿ ë°ì´í„° ì¤€ë¹„
            template_data = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'analysis_period': f'ìµœê·¼ {hours}ì‹œê°„',
                'avg_response_time': stats.get('avg_response_time', 0),
                'max_response_time': stats.get('max_response_time', 0),
                'response_time_std': stats.get('response_time_std', 0),
                'avg_memory_usage': stats.get('avg_memory_usage', 0),
                'max_memory_usage': stats.get('max_memory_usage', 0),
                'memory_efficiency': stats.get('memory_efficiency', 0),
                'avg_coherence': stats.get('avg_coherence', 0),
                'context_retention': stats.get('context_retention', 0),
                'degradation_risk': stats.get('degradation_risk', 0),
                'trend_analysis': trend_analysis,
                'issues': issues,
                'recommendations': recommendations
            }
            
            # í…œí”Œë¦¿ ë Œë”ë§
            template_file = self.templates_path / 'performance_analysis.md'
            template = Template(template_file.read_text(encoding='utf-8'))
            content = template.render(**template_data)
            
            # ë³´ê³ ì„œ ì €ì¥
            report_id = f"performance_{int(datetime.now().timestamp())}"
            report_file = self.monitor.reports_path / f"{report_id}.md"
            report_file.write_text(content, encoding='utf-8')
            
            return {
                'id': report_id,
                'type': 'performance_analysis',
                'file_path': str(report_file),
                'content': content,
                'data': template_data,
                'generated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.monitor.log(f"ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}", "ERROR")
            return {}
    
    def _generate_insights(self, health: Dict, sessions: List) -> List[str]:
        """ì¸ì‚¬ì´íŠ¸ ìƒì„± - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„"""
        insights = []
        
        # CPU ì‚¬ìš©ë¥  ë¶„ì„
        cpu_percent = health.get('system', {}).get('cpu_percent', 0)
        if cpu_percent > 70:
            insights.append(f"âš ï¸ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({cpu_percent:.1f}%). ì‹œìŠ¤í…œ ë¶€í•˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        elif cpu_percent < 5:
            insights.append(f"âœ… CPU ì‚¬ìš©ë¥ ì´ ë‚®ê³  ì•ˆì •ì ì…ë‹ˆë‹¤ ({cpu_percent:.1f}%).")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë¶„ì„
        memory_percent = health.get('system', {}).get('memory_percent', 0)
        if memory_percent > 80:
            insights.append(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({memory_percent:.1f}%). ë©”ëª¨ë¦¬ ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        elif memory_percent > 60:
            insights.append(f"ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ì ì • ìˆ˜ì¤€ì…ë‹ˆë‹¤ ({memory_percent:.1f}%).")
        
        # ì„¸ì…˜ ë¶„ì„
        if len(sessions) > 5:
            insights.append(f"ğŸ“ˆ í™œì„± ì„¸ì…˜ì´ ë§ìŠµë‹ˆë‹¤ ({len(sessions)}ê°œ). ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.")
        elif len(sessions) > 0:
            active_sessions_with_data = [s for s in sessions if s.get('message_count', 0) > 0]
            if len(active_sessions_with_data) == 0:
                insights.append(f"ğŸ’¤ {len(sessions)}ê°œì˜ ì„¸ì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆì§€ë§Œ ì•„ì§ í™œë™ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                insights.append(f"ğŸš€ {len(active_sessions_with_data)}ê°œì˜ ì„¸ì…˜ì—ì„œ í™œë°œí•œ í™œë™ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
        else:
            insights.append("ğŸ”„ í˜„ì¬ í™œì„± ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # ì˜¤ë¥˜ ë¶„ì„ - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜
        errors_24h = health.get('gpt5', {}).get('errors_24h', 0)
        if errors_24h > 10:
            insights.append(f"ğŸ”´ 24ì‹œê°„ ë‚´ ì˜¤ë¥˜ê°€ ë§ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤ ({errors_24h}ê±´). ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        elif errors_24h > 0:
            insights.append(f"âš ï¸ 24ì‹œê°„ ë‚´ {errors_24h}ê±´ì˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ì„ ê³„ì†í•˜ì„¸ìš”.")
        else:
            insights.append("âœ… 24ì‹œê°„ ë‚´ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì•ˆì •ì ì…ë‹ˆë‹¤.")
        
        # ëª¨ë‹ˆí„°ë§ ìƒíƒœ ë¶„ì„
        monitoring_status = health.get('gpt5', {}).get('monitoring_status', 'unknown')
        if monitoring_status == 'inactive':
            insights.append("ğŸ”§ GPT-5 ëª¨ë‹ˆí„°ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í™œì„±í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        return insights
    
    def _generate_recommendations(self, health: Dict, sessions: List) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if health.get('system', {}).get('disk_free_gb', 0) < 5:
            recommendations.append("ë””ìŠ¤í¬ ê³µê°„ì„ ì •ë¦¬í•˜ì—¬ ì—¬ìœ  ê³µê°„ì„ í™•ë³´í•˜ì„¸ìš”.")
        
        if len(sessions) == 0:
            recommendations.append("ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì‹œì‘í•˜ì—¬ ì‹œìŠ¤í…œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.")
        
        recommendations.append("ì •ê¸°ì ì¸ ì‹œìŠ¤í…œ ë°±ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
        recommendations.append("ëª¨ë‹ˆí„°ë§ ë°ì´í„°ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.")
        
        return recommendations
    
    def _calculate_performance_stats(self, performance_data: List) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ê³„ì‚°"""
        if not performance_data:
            return {}
        
        # ëª¨ë“  ì„±ëŠ¥ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        all_response_times = []
        all_memory_usage = []
        all_coherence_scores = []
        
        for session_data in performance_data:
            if session_data.get('performance_trend'):
                for perf in session_data['performance_trend']:
                    all_response_times.append(perf[1])  # response_time
            
            if session_data.get('memory_trend'):
                for mem in session_data['memory_trend']:
                    all_memory_usage.append(mem[4])  # total_mb
            
            if session_data.get('context_trend'):
                for ctx in session_data['context_trend']:
                    all_coherence_scores.append(ctx[2])  # coherence_score
        
        stats = {}
        
        if all_response_times:
            stats['avg_response_time'] = sum(all_response_times) / len(all_response_times)
            stats['max_response_time'] = max(all_response_times)
            stats['response_time_std'] = pd.Series(all_response_times).std() if len(all_response_times) > 1 else 0
        
        if all_memory_usage:
            stats['avg_memory_usage'] = sum(all_memory_usage) / len(all_memory_usage)
            stats['max_memory_usage'] = max(all_memory_usage)
            stats['memory_efficiency'] = min(all_memory_usage) / max(all_memory_usage) if max(all_memory_usage) > 0 else 0
        
        if all_coherence_scores:
            stats['avg_coherence'] = sum(all_coherence_scores) / len(all_coherence_scores)
            stats['context_retention'] = (sum(1 for score in all_coherence_scores if score > 0.8) / len(all_coherence_scores)) * 100
            stats['degradation_risk'] = sum(1 for score in all_coherence_scores if score < 0.7) / len(all_coherence_scores)
        
        return stats
    
    def _analyze_trends(self, performance_data: List) -> str:
        """íŠ¸ë Œë“œ ë¶„ì„"""
        if not performance_data:
            return "ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        analysis = []
        analysis.append("ğŸ“ˆ **ë©”ëª¨ë¦¬ ì‚¬ìš© íŠ¸ë Œë“œ**: ì•ˆì •ì ì¸ ì‚¬ìš© íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.")
        analysis.append("âš¡ **ì‘ë‹µ ì†ë„ íŠ¸ë Œë“œ**: í‰ê·  ì‘ë‹µ ì‹œê°„ì´ í—ˆìš© ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")
        analysis.append("ğŸ¯ **ë§¥ë½ í’ˆì§ˆ íŠ¸ë Œë“œ**: ì¼ê´€ì„± ìˆëŠ” ë§¥ë½ ìœ ì§€ê°€ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.")
        
        return "\n".join(analysis)
    
    def _identify_issues(self, stats: Dict, performance_data: List) -> List[Dict]:
        """ë¬¸ì œì  ì‹ë³„"""
        issues = []
        
        if stats.get('avg_response_time', 0) > 2000:
            issues.append({
                'type': 'ì‘ë‹µ ì†ë„ ì €í•˜',
                'description': 'í‰ê·  ì‘ë‹µ ì‹œê°„ì´ 2ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.',
                'severity': 'ì¤‘ê°„',
                'recommendation': 'API í˜¸ì¶œ ìµœì í™” ë° ìºì‹± ì „ëµ ê²€í† '
            })
        
        if stats.get('memory_efficiency', 1) < 0.5:
            issues.append({
                'type': 'ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì €í•˜',
                'description': 'ë©”ëª¨ë¦¬ ì‚¬ìš© íš¨ìœ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤.',
                'severity': 'ë†’ìŒ',
                'recommendation': 'ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”'
            })
        
        if stats.get('degradation_risk', 0) > 0.3:
            issues.append({
                'type': 'ë§¥ë½ í’ˆì§ˆ ì €í•˜ ìœ„í—˜',
                'description': 'ë§¥ë½ ì¼ê´€ì„±ì´ ì €í•˜ë  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.',
                'severity': 'ì¤‘ê°„',
                'recommendation': 'ë§¥ë½ ìœˆë„ìš° í¬ê¸° ì¡°ì • ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ '
            })
        
        return issues
    
    def _generate_performance_recommendations(self, stats: Dict, issues: List) -> List[Dict]:
        """ì„±ëŠ¥ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = [
            {
                'title': 'ì •ê¸°ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§',
                'description': 'ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ë¬¸ì œë¥¼ ì¡°ê¸°ì— ë°œê²¬í•˜ì„¸ìš”.',
                'priority': 'ë†’ìŒ'
            },
            {
                'title': 'ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”',
                'description': 'ë¶ˆí•„ìš”í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì´ê³  íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.',
                'priority': 'ì¤‘ê°„'
            },
            {
                'title': 'ë§¥ë½ í’ˆì§ˆ ê°œì„ ',
                'description': 'ë§¥ë½ ìœ ì§€ ì•Œê³ ë¦¬ì¦˜ì„ ìµœì í™”í•˜ì—¬ ì¼ê´€ì„±ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.',
                'priority': 'ì¤‘ê°„'
            }
        ]
        
        # ë¬¸ì œì ì— ë”°ë¥¸ ì¶”ê°€ ê¶Œì¥ì‚¬í•­
        for issue in issues:
            if issue['severity'] == 'ë†’ìŒ':
                recommendations.insert(0, {
                    'title': f"{issue['type']} ê¸´ê¸‰ ëŒ€ì‘",
                    'description': issue['recommendation'],
                    'priority': 'ê¸´ê¸‰'
                })
        
        return recommendations


# ì „ì—­ ë³´ê³ ì„œ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤
_report_generator = None

def get_report_generator() -> GPT5ReportGenerator:
    """ë³´ê³ ì„œ ìƒì„±ê¸° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _report_generator
    if _report_generator is None:
        _report_generator = GPT5ReportGenerator()
    return _report_generator