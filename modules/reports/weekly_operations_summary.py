#!/usr/bin/env python3
# =========================================================
# VELOS ì£¼ê°„ ìš´ì˜ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±ê¸°
# ì¼ì£¼ì¼ê°„ì˜ ì‹œìŠ¤í…œ ë³€í™”ì™€ ì„±ê³¼ ë¶„ì„
# =========================================================

import json
import time
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, Counter

# Use correct path for sandbox environment  
ROOT = Path("/home/user/webapp")

class WeeklyOperationsAnalyzer:
    """ì£¼ê°„ ìš´ì˜ ë¶„ì„ê¸°"""
    
    def __init__(self, weeks_back: int = 1):
        self.root = ROOT
        self.logs_dir = self.root / "data" / "logs"
        self.memory_dir = self.root / "data" / "memory"
        self.reports_dir = self.root / "data" / "reports"
        self.weeks_back = weeks_back
        
        # ì‹œê°„ ë²”ìœ„ ì„¤ì •
        self.end_date = datetime.now()
        self.start_date = self.end_date - timedelta(days=7 * weeks_back)
        
    def load_json_safe(self, file_path: Path) -> Dict[str, Any]:
        """ì•ˆì „í•œ JSON ë¡œë”©"""
        if not file_path.exists():
            return {}
        try:
            return json.loads(file_path.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"[WARN] JSON ë¡œë”© ì‹¤íŒ¨ {file_path}: {e}")
            return {}
    
    def analyze_memory_growth(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ë°ì´í„° ì¦ê°€ ë¶„ì„"""
        memory_analysis = {
            "total_records": 0,
            "growth_rate": "unknown",
            "activity_pattern": {},
            "top_topics": [],
            "insights": []
        }
        
        # í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ
        health_data = self.load_json_safe(self.logs_dir / "system_health.json")
        current_records = health_data.get("memory_tick_stats", {}).get("db_records", 0)
        memory_analysis["total_records"] = current_records
        
        # ë©”ëª¨ë¦¬ íŒŒì¼ ë¶„ì„
        memory_file = self.memory_dir / "autosave_inbox.jsonl"
        if memory_file.exists():
            try:
                lines = memory_file.read_text(encoding="utf-8").strip().split('\n')
                valid_entries = []
                topic_counter = Counter()
                
                for line in lines:
                    if line.strip():
                        try:
                            entry = json.loads(line)
                            valid_entries.append(entry)
                            
                            # ì£¼ì œ ë¶„ì„ (íƒœê·¸ë‚˜ ë‚´ìš©ì—ì„œ)
                            tags = entry.get("tags", [])
                            raw_content = entry.get("raw", "").lower()
                            
                            for tag in tags:
                                topic_counter[tag] += 1
                            
                            # í‚¤ì›Œë“œ ì¶”ì¶œ
                            keywords = ["gpt", "slack", "memory", "report", "system", "api", "error", "test"]
                            for keyword in keywords:
                                if keyword in raw_content:
                                    topic_counter[keyword] += 1
                                    
                        except json.JSONDecodeError:
                            continue
                
                memory_analysis["activity_pattern"]["recent_entries"] = len(valid_entries)
                memory_analysis["top_topics"] = topic_counter.most_common(5)
                
                if len(valid_entries) > 0:
                    memory_analysis["insights"].append(f"ğŸ“ˆ ì£¼ê°„ ìƒˆë¡œìš´ í•™ìŠµ í•­ëª©: {len(valid_entries)}ê±´")
                    
                    if topic_counter:
                        top_topic = topic_counter.most_common(1)[0]
                        memory_analysis["insights"].append(f"ğŸ”¥ ê°€ì¥ í™œë°œí•œ ì£¼ì œ: {top_topic[0]} ({top_topic[1]}ê±´)")
            except Exception as e:
                memory_analysis["insights"].append(f"âš ï¸ ë©”ëª¨ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return memory_analysis
    
    def analyze_system_stability(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì•ˆì •ì„± ë¶„ì„"""
        stability = {
            "uptime_score": "unknown",
            "error_incidents": [],
            "recovery_actions": [],
            "stability_trend": "stable",
            "recommendations": []
        }
        
        health_data = self.load_json_safe(self.logs_dir / "system_health.json")
        
        # ì‹œìŠ¤í…œ ë¬´ê²°ì„± íˆìŠ¤í† ë¦¬
        if health_data:
            # í˜„ì¬ ì´ìŠˆ ë¶„ì„
            sys_integrity = health_data.get("system_integrity", {})
            if not sys_integrity.get("integrity_ok", True):
                issues = sys_integrity.get("details", {}).get("process_issues", [])
                for issue in issues:
                    stability["error_incidents"].append({
                        "type": "process_failure",
                        "description": issue,
                        "severity": "high" if "autosave" in issue else "medium"
                    })
                    
                    if "autosave" in issue:
                        stability["recovery_actions"].append("autosave_runner ì¬ì‹œì‘ í•„ìš”")
            
            # ìŠ¤ëƒ…ìƒ· ìƒíƒœ
            if health_data.get("snapshot_integrity_ok"):
                stability["recovery_actions"].append("ë°±ì—… ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì¤‘")
            
            # ë©”ëª¨ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒíƒœ
            pipeline_ok = health_data.get("memory_pipeline_last_test_ok", False)
            if pipeline_ok:
                stability["uptime_score"] = "ì–‘í˜¸"
            else:
                stability["error_incidents"].append({
                    "type": "pipeline_failure", 
                    "description": "ë©”ëª¨ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨",
                    "severity": "medium"
                })
        
        # ì•ˆì •ì„± í‰ê°€
        error_count = len(stability["error_incidents"])
        if error_count == 0:
            stability["stability_trend"] = "ë§¤ìš° ì•ˆì •"
            stability["recommendations"].append("âœ… ì‹œìŠ¤í…œ ì•ˆì •ì„± ìš°ìˆ˜ - í˜„ ìƒíƒœ ìœ ì§€")
        elif error_count <= 2:
            stability["stability_trend"] = "ì£¼ì˜ ê´€ì°°"
            stability["recommendations"].append("âš ï¸ ì†Œê·œëª¨ ì´ìŠˆ ë°œê²¬ - ì •ê¸° ì ê²€ ê¶Œì¥")
        else:
            stability["stability_trend"] = "ë¶ˆì•ˆì •"
            stability["recommendations"].append("ğŸš¨ ë‹¤ìˆ˜ ì´ìŠˆ ë°œê²¬ - ì¦‰ì‹œ ì ê²€ í•„ìš”")
        
        return stability
    
    def analyze_performance_trends(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
        performance = {
            "response_efficiency": "unknown",
            "resource_utilization": "unknown", 
            "bottleneck_analysis": [],
            "optimization_opportunities": [],
            "weekly_summary": {}
        }
        
        health_data = self.load_json_safe(self.logs_dir / "system_health.json")
        
        if health_data:
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
            memory_stats = health_data.get("memory_tick_stats", {})
            db_records = memory_stats.get("db_records", 0)
            
            if db_records > 0:
                if db_records < 500:
                    performance["resource_utilization"] = "ê²½ëŸ‰"
                elif db_records < 1500:
                    performance["resource_utilization"] = "ì ì •"
                else:
                    performance["resource_utilization"] = "ë†’ìŒ"
                    performance["optimization_opportunities"].append(
                        f"ë©”ëª¨ë¦¬ ë ˆì½”ë“œ {db_records:,}ê°œ - ì•„ì¹´ì´ë¹™ ê¶Œì¥"
                    )
            
            # í•«ë²„í¼ ì„±ëŠ¥
            if health_data.get("hotbuf_ok"):
                rebuild_count = health_data.get("hotbuf_rebuild_count", 0)
                performance["response_efficiency"] = "ì •ìƒ"
                
                if rebuild_count > 30:
                    performance["bottleneck_analysis"].append(
                        f"í•«ë²„í¼ ì¬ë¹Œë“œ ë¹ˆë²ˆí•¨ ({rebuild_count}íšŒ) - TTL ìµœì í™” í•„ìš”"
                    )
            
            # ë””ìŠ¤íŒ¨ì¹˜ ì„±ëŠ¥
            if health_data.get("dispatch_last_ok"):
                targets = health_data.get("dispatch_last_targets", [])
                performance["weekly_summary"]["dispatch_channels"] = len(targets)
                performance["optimization_opportunities"].append(
                    f"âœ… {len(targets)}ê°œ ì±„ë„ ë””ìŠ¤íŒ¨ì¹˜ ì •ìƒ ì‘ë™"
                )
        
        return performance
        
    def generate_weekly_insights(self) -> List[str]:
        """ì£¼ê°„ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        # ì‹œê°„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        current_hour = datetime.now().hour
        if 9 <= current_hour <= 17:
            insights.append("ğŸ“… ì—…ë¬´ì‹œê°„ ì¤‘ ë³´ê³ ì„œ ìƒì„± - ì‹œìŠ¤í…œ í™œì„± ìƒíƒœ")
        else:
            insights.append("ğŸŒ™ ì—…ë¬´ì™¸ì‹œê°„ ë³´ê³ ì„œ ìƒì„± - ìë™í™” ì‹œìŠ¤í…œ ì‘ë™")
        
        # ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        health_data = self.load_json_safe(self.logs_dir / "system_health.json")
        if health_data:
            session_count = health_data.get("session_bootstrap_count", 0)
            if session_count > 300:
                insights.append(f"ğŸš€ ë†’ì€ ì„¸ì…˜ í™œë™ ({session_count}íšŒ) - ì‹œìŠ¤í…œ í™œë°œíˆ ì‚¬ìš© ì¤‘")
            
            last_flush_moved = health_data.get("last_flush_moved", 0)
            if last_flush_moved > 500:
                insights.append(f"ğŸ’¾ ëŒ€ëŸ‰ ë°ì´í„° í”ŒëŸ¬ì‹œ ({last_flush_moved}ê±´) - í™œë°œí•œ í•™ìŠµ í™œë™")
        
        return insights
    
    def generate_title(self, analysis_results: Dict[str, Any]) -> str:
        """ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ë™ì  ì œëª© ìƒì„±"""
        week_period = f"{self.start_date.strftime('%m/%d')}-{self.end_date.strftime('%m/%d')}"
        
        # ì•ˆì •ì„± ê¸°ë°˜ ì œëª© ê²°ì •
        stability = analysis_results.get("stability", {})
        trend = stability.get("stability_trend", "unknown")
        
        title_templates = {
            "ë§¤ìš° ì•ˆì •": f"âœ… VELOS ì£¼ê°„ ìš´ì˜ ë³´ê³ ì„œ - ì•ˆì •ì  ìš´ì˜ ({week_period})",
            "ì£¼ì˜ ê´€ì°°": f"âš ï¸ VELOS ì£¼ê°„ ìš´ì˜ ë³´ê³ ì„œ - ì£¼ì˜ì‚¬í•­ í¬í•¨ ({week_period})",
            "ë¶ˆì•ˆì •": f"ğŸš¨ VELOS ì£¼ê°„ ìš´ì˜ ë³´ê³ ì„œ - ê°œì„  í•„ìš” ({week_period})",
            "unknown": f"ğŸ“Š VELOS ì£¼ê°„ ìš´ì˜ ë³´ê³ ì„œ ({week_period})"
        }
        
        return title_templates.get(trend, title_templates["unknown"])
    
    def generate_weekly_content(self) -> Dict[str, Any]:
        """ì „ì²´ ì£¼ê°„ ë³´ê³ ì„œ ì½˜í…ì¸  ìƒì„±"""
        print(f"[INFO] {self.start_date.strftime('%Y-%m-%d')} ~ {self.end_date.strftime('%Y-%m-%d')} ì£¼ê°„ ë¶„ì„ ì¤‘...")
        
        # ë¶„ì„ ì‹¤í–‰
        memory_analysis = self.analyze_memory_growth()
        stability_analysis = self.analyze_system_stability()
        performance_analysis = self.analyze_performance_trends()
        weekly_insights = self.generate_weekly_insights()
        
        analysis_results = {
            "memory": memory_analysis,
            "stability": stability_analysis,
            "performance": performance_analysis
        }
        
        # ì œëª© ìƒì„±
        title = self.generate_title(analysis_results)
        
        # ì¢…í•© í‰ê°€
        overall_score = self.calculate_overall_score(analysis_results)
        
        return {
            "title": title,
            "period": f"{self.start_date.strftime('%Y-%m-%d')} ~ {self.end_date.strftime('%Y-%m-%d')}",
            "timestamp": datetime.now().isoformat(),
            "overall_score": overall_score,
            "memory": memory_analysis,
            "stability": stability_analysis,
            "performance": performance_analysis,
            "insights": weekly_insights,
            "next_week_actions": self.generate_action_items(analysis_results)
        }
    
    def calculate_overall_score(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        score = {
            "stability": 0,
            "performance": 0,
            "growth": 0,
            "overall": "B",
            "summary": ""
        }
        
        # ì•ˆì •ì„± ì ìˆ˜
        stability = analysis_results["stability"]
        error_count = len(stability["error_incidents"])
        if error_count == 0:
            score["stability"] = 95
        elif error_count <= 2:
            score["stability"] = 75
        else:
            score["stability"] = 50
        
        # ì„±ëŠ¥ ì ìˆ˜  
        performance = analysis_results["performance"]
        if performance["response_efficiency"] == "ì •ìƒ":
            score["performance"] = 90
        else:
            score["performance"] = 60
            
        # ì„±ì¥ ì ìˆ˜
        memory = analysis_results["memory"]
        if memory["total_records"] > 1000:
            score["growth"] = 85
        elif memory["total_records"] > 500:
            score["growth"] = 70
        else:
            score["growth"] = 50
        
        # ì¢…í•© í‰ê°€
        avg_score = (score["stability"] + score["performance"] + score["growth"]) / 3
        if avg_score >= 90:
            score["overall"] = "A+"
        elif avg_score >= 80:
            score["overall"] = "A"
        elif avg_score >= 70:
            score["overall"] = "B+"
        elif avg_score >= 60:
            score["overall"] = "B"
        else:
            score["overall"] = "C"
            
        score["summary"] = f"ì•ˆì •ì„± {score['stability']}ì , ì„±ëŠ¥ {score['performance']}ì , ì„±ì¥ {score['growth']}ì "
        
        return score
    
    def generate_action_items(self, analysis_results: Dict[str, Any]) -> List[str]:
        """ë‹¤ìŒ ì£¼ ì•¡ì…˜ ì•„ì´í…œ ìƒì„±"""
        actions = []
        
        # ì•ˆì •ì„± ê¸°ë°˜ ì•¡ì…˜
        stability = analysis_results["stability"]
        for action in stability["recommendations"]:
            actions.append(action)
        
        # ì„±ëŠ¥ ê¸°ë°˜ ì•¡ì…˜
        performance = analysis_results["performance"]
        for opportunity in performance["optimization_opportunities"]:
            if "ê¶Œì¥" in opportunity or "í•„ìš”" in opportunity:
                actions.append(f"ğŸ¯ {opportunity}")
        
        # ê¸°ë³¸ ì•¡ì…˜ë“¤
        if not actions:
            actions.append("âœ… í˜„ì¬ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì§€ì†")
            actions.append("ğŸ“Š ë‹¤ìŒ ì£¼ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘")
        
        return actions

def generate_weekly_operations_report(weeks_back: int = 1) -> str:
    """ì£¼ê°„ ìš´ì˜ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    analyzer = WeeklyOperationsAnalyzer(weeks_back)
    report_data = analyzer.generate_weekly_content()
    
    # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„±
    report_lines = []
    
    # ì œëª© ë° ê¸°ê°„
    report_lines.append(f"# {report_data['title']}")
    report_lines.append(f"**ë¶„ì„ ê¸°ê°„**: {report_data['period']}")
    report_lines.append("")
    
    # ì¢…í•© í‰ê°€
    overall = report_data['overall_score']
    report_lines.append("## ğŸ¯ ì¢…í•© í‰ê°€")
    report_lines.append(f"**ì¢…í•© ë“±ê¸‰**: {overall['overall']}")
    report_lines.append(f"**ìƒì„¸ ì ìˆ˜**: {overall['summary']}")
    report_lines.append("")
    
    # ë©”ëª¨ë¦¬ & í•™ìŠµ í˜„í™©
    memory = report_data['memory']
    report_lines.append("## ğŸ§  ë©”ëª¨ë¦¬ & í•™ìŠµ í˜„í™©")
    report_lines.append(f"- **ì´ ë©”ëª¨ë¦¬ ë ˆì½”ë“œ**: {memory['total_records']:,}ê°œ")
    report_lines.append(f"- **ì£¼ê°„ í™œë™**: {memory['activity_pattern'].get('recent_entries', 0)}ê±´")
    
    if memory['top_topics']:
        report_lines.append("- **ì£¼ìš” í•™ìŠµ ì£¼ì œ**:")
        for topic, count in memory['top_topics']:
            report_lines.append(f"  - {topic}: {count}ê±´")
    
    for insight in memory['insights']:
        report_lines.append(f"- {insight}")
    report_lines.append("")
    
    # ì‹œìŠ¤í…œ ì•ˆì •ì„±
    stability = report_data['stability']
    report_lines.append("## ğŸ›¡ï¸ ì‹œìŠ¤í…œ ì•ˆì •ì„±")
    report_lines.append(f"- **ì•ˆì •ì„± í‰ê°€**: {stability['stability_trend']}")
    report_lines.append(f"- **ê°€ë™ ì‹œê°„**: {stability['uptime_score']}")
    
    if stability['error_incidents']:
        report_lines.append("- **ë°œê²¬ëœ ì´ìŠˆ**:")
        for incident in stability['error_incidents']:
            severity_icon = "ğŸš¨" if incident['severity'] == 'high' else "âš ï¸"
            report_lines.append(f"  - {severity_icon} {incident['description']}")
    
    if stability['recovery_actions']:
        report_lines.append("- **ë³µêµ¬ ì¡°ì¹˜**:")
        for action in stability['recovery_actions']:
            report_lines.append(f"  - {action}")
    report_lines.append("")
    
    # ì„±ëŠ¥ ë¶„ì„
    performance = report_data['performance']
    report_lines.append("## âš¡ ì„±ëŠ¥ ë¶„ì„")
    report_lines.append(f"- **ì‘ë‹µ íš¨ìœ¨ì„±**: {performance['response_efficiency']}")
    report_lines.append(f"- **ë¦¬ì†ŒìŠ¤ í™œìš©ë„**: {performance['resource_utilization']}")
    
    if performance['bottleneck_analysis']:
        report_lines.append("- **ë³‘ëª© ì§€ì **:")
        for bottleneck in performance['bottleneck_analysis']:
            report_lines.append(f"  - âš ï¸ {bottleneck}")
    
    if performance['optimization_opportunities']:
        report_lines.append("- **ìµœì í™” ê¸°íšŒ**:")
        for opportunity in performance['optimization_opportunities']:
            report_lines.append(f"  - {opportunity}")
    report_lines.append("")
    
    # ì£¼ê°„ ì¸ì‚¬ì´íŠ¸
    if report_data['insights']:
        report_lines.append("## ğŸ’¡ ì£¼ê°„ ì¸ì‚¬ì´íŠ¸")
        for insight in report_data['insights']:
            report_lines.append(f"- {insight}")
        report_lines.append("")
    
    # ë‹¤ìŒ ì£¼ ì•¡ì…˜ í”Œëœ
    report_lines.append("## ğŸ¯ ë‹¤ìŒ ì£¼ ì•¡ì…˜ í”Œëœ")
    for action in report_data['next_week_actions']:
        report_lines.append(f"- {action}")
    report_lines.append("")
    
    # ìƒì„± ì •ë³´
    report_lines.append("---")
    report_lines.append(f"*ìƒì„±ì‹œê°„: {report_data['timestamp']}*")
    report_lines.append("*VELOS ì£¼ê°„ ìš´ì˜ ìš”ì•½ ë³´ê³ ì„œ v1.0*")
    
    return "\n".join(report_lines)

if __name__ == "__main__":
    report_content = generate_weekly_operations_report()
    print(report_content)